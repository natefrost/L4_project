{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7b0nW2cPpNm",
        "outputId": "633ff4b3-28ec-4b04-d148-9bbb978f405e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.load('/content/drive/My Drive/Colab Notebooks/labels.npy')\n",
        "audios = np.load('/content/drive/My Drive/Colab Notebooks/audios.npy')"
      ],
      "metadata": {
        "id": "Nz035mXrwbXP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "khJARSxpYP1i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A_train, A_test, y_train, y_test = train_test_split(audios, labels, test_size=0.25, random_state=1)"
      ],
      "metadata": {
        "id": "iGAdy9Bnpl-Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.layers import LSTM, Input, Flatten, Embedding, Conv1D, Conv2D, Dropout, MaxPooling2D"
      ],
      "metadata": {
        "id": "7AO40jnpqDHW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yt = label_binarize(y_train, classes=['angry', 'happy', 'sad', 'neutral', 'other', 'X'])"
      ],
      "metadata": {
        "id": "2CtbIhEBq2mK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#specs = np.load('/content/drive/My Drive/Colab Notebooks/specs.npy')\n",
        "#S_train, S_test, = train_test_split(specs, test_size=0.25, random_state=1)"
      ],
      "metadata": {
        "id": "zkO1EsoEtEeC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A_train=A_train.reshape(A_train.shape[0],int(A_train.shape[1]/64),64)\n",
        "A_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHxgA_GtuMtw",
        "outputId": "c5e5ffd3-8f0c-49a7-fde9-5d3cf98c4255"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(954, 5287, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_mod_1():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(512, return_sequences=True, input_shape=(5287,64)))\n",
        "    model.add(LSTM(256, return_sequences=False))\n",
        "\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.add(Dense(6))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "_-m4xAIwriqU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mod = lstm_mod_1()\n",
        "test_mod.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnIuyFlismhi",
        "outputId": "5ab5b721-5128-4541-e3c2-cc956bcfbc17"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_10 (LSTM)              (None, 5287, 512)         1181696   \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 256)               787456    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 6)                 774       \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,167,174\n",
            "Trainable params: 2,167,174\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trial\n",
        "#hist = test_mod.fit(A_train, yt, batch_size=53, epochs=15, verbose=1, shuffle=False,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "jnFgnP57v-u4",
        "outputId": "4c72cbdf-64c0-4d99-d098-d0a249963ade"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "18/18 [==============================] - 27s 1s/step - loss: 1.7339 - accuracy: 0.2904\n",
            "Epoch 2/15\n",
            "18/18 [==============================] - 24s 1s/step - loss: 1.6765 - accuracy: 0.4109\n",
            "Epoch 3/15\n",
            "18/18 [==============================] - 25s 1s/step - loss: 1.6614 - accuracy: 0.4109\n",
            "Epoch 4/15\n",
            "18/18 [==============================] - 25s 1s/step - loss: 1.6473 - accuracy: 0.4109\n",
            "Epoch 5/15\n",
            "18/18 [==============================] - 25s 1s/step - loss: 1.6338 - accuracy: 0.4109\n",
            "Epoch 6/15\n",
            "18/18 [==============================] - 25s 1s/step - loss: 1.6211 - accuracy: 0.4109\n",
            "Epoch 7/15\n",
            "18/18 [==============================] - 26s 1s/step - loss: 1.6088 - accuracy: 0.4109\n",
            "Epoch 8/15\n",
            "18/18 [==============================] - 25s 1s/step - loss: 1.5973 - accuracy: 0.4109\n",
            "Epoch 9/15\n",
            " 2/18 [==>...........................] - ETA: 22s - loss: 1.5721 - accuracy: 0.4057"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-dda5529d875b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m53\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_mod_2():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(512, return_sequences=True, input_shape=(5287,64)))\n",
        "    model.add(LSTM(256, return_sequences=False))\n",
        "\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(6))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Gw-ASMGnSGD5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testmod = lstm_mod_2()\n",
        "testmod.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVcxCCXXMJjt",
        "outputId": "029114d2-845f-4f0a-87f7-cb545f0d4e05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 5287, 512)         1181696   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 256)               787456    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               131584    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,167,174\n",
            "Trainable params: 2,167,174\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = testmod.fit(A_train, yt, batch_size=53, epochs=15, verbose=1, shuffle=False,validation_split=0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lwzjY8HMlv3",
        "outputId": "226b4596-e7d4-4b8a-c7b6-f2535a4a833d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "14/14 [==============================] - 29s 2s/step - loss: 1.8634 - accuracy: 0.2434 - val_loss: 1.6094 - val_accuracy: 0.2176\n",
            "Epoch 2/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4823 - accuracy: 0.3972 - val_loss: 1.5321 - val_accuracy: 0.2176\n",
            "Epoch 3/15\n",
            "14/14 [==============================] - 22s 2s/step - loss: 1.4626 - accuracy: 0.3972 - val_loss: 1.5096 - val_accuracy: 0.2176\n",
            "Epoch 4/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4579 - accuracy: 0.3972 - val_loss: 1.5203 - val_accuracy: 0.2176\n",
            "Epoch 5/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4574 - accuracy: 0.3972 - val_loss: 1.4856 - val_accuracy: 0.4142\n",
            "Epoch 6/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4535 - accuracy: 0.4098 - val_loss: 1.4810 - val_accuracy: 0.4142\n",
            "Epoch 7/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4517 - accuracy: 0.4098 - val_loss: 1.4699 - val_accuracy: 0.4142\n",
            "Epoch 8/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4508 - accuracy: 0.4098 - val_loss: 1.4674 - val_accuracy: 0.4142\n",
            "Epoch 9/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4491 - accuracy: 0.4098 - val_loss: 1.4655 - val_accuracy: 0.4142\n",
            "Epoch 10/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4486 - accuracy: 0.4098 - val_loss: 1.4718 - val_accuracy: 0.4142\n",
            "Epoch 11/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4481 - accuracy: 0.4098 - val_loss: 1.4585 - val_accuracy: 0.4142\n",
            "Epoch 12/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4464 - accuracy: 0.4098 - val_loss: 1.4581 - val_accuracy: 0.4142\n",
            "Epoch 13/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4461 - accuracy: 0.4098 - val_loss: 1.4560 - val_accuracy: 0.4142\n",
            "Epoch 14/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4450 - accuracy: 0.4098 - val_loss: 1.4581 - val_accuracy: 0.4142\n",
            "Epoch 15/15\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.4450 - accuracy: 0.4098 - val_loss: 1.4542 - val_accuracy: 0.4142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "As_train = 0"
      ],
      "metadata": {
        "id": "ZzymsK5hMsZv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_mod_3():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(512, return_sequences=True, input_shape=(5287,64)))\n",
        "    model.add(LSTM(256, return_sequences=False))\n",
        "    \n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(6))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ae_D2RJoOt_I"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testmod = lstm_mod_3()\n",
        "testmod.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5ZYq72cO09e",
        "outputId": "9db7ccea-f54d-48d2-9af3-32f32210cb8d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_9 (LSTM)               (None, 5287, 512)         1181696   \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 256)               787456    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 6)                 774       \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,265,734\n",
            "Trainable params: 2,265,734\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = testmod.fit(A_train, yt, batch_size=53, epochs=10, verbose=1, shuffle=False,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n53rb8YpPEMz",
        "outputId": "f6ae892e-3092-4b1f-ee9d-20d7bb01d60d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 25s 1s/step - loss: 1.7406 - accuracy: 0.3028 - val_loss: 1.5060 - val_accuracy: 0.4136\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 22s 1s/step - loss: 1.4962 - accuracy: 0.3879 - val_loss: 1.4648 - val_accuracy: 0.4136\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 23s 2s/step - loss: 1.4709 - accuracy: 0.4102 - val_loss: 1.4741 - val_accuracy: 0.4136\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 23s 2s/step - loss: 1.4660 - accuracy: 0.4024 - val_loss: 1.4436 - val_accuracy: 0.4136\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 22s 1s/step - loss: 1.4613 - accuracy: 0.4063 - val_loss: 1.4426 - val_accuracy: 0.4136\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 22s 1s/step - loss: 1.4619 - accuracy: 0.4089 - val_loss: 1.4312 - val_accuracy: 0.4136\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 22s 1s/step - loss: 1.4559 - accuracy: 0.4102 - val_loss: 1.4285 - val_accuracy: 0.4136\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 22s 1s/step - loss: 1.4546 - accuracy: 0.4102 - val_loss: 1.4276 - val_accuracy: 0.4136\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 22s 1s/step - loss: 1.4536 - accuracy: 0.4102 - val_loss: 1.4265 - val_accuracy: 0.4136\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 22s 1s/step - loss: 1.4523 - accuracy: 0.4102 - val_loss: 1.4282 - val_accuracy: 0.4136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7xeHd1DhPfG1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}