{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52cbac34",
   "metadata": {},
   "source": [
    "## End-to-End model for classification emotions from audio files.\n",
    "\n",
    "This is a follow up to the preliminary file 'model_first', where data processing and base models were made.\n",
    "\n",
    "The base model evaluates at 52.8% accuracy.\n",
    "\n",
    "Let's see if I can improve the performance using and end-to-end deep learning model.\n",
    "\n",
    "I will first start with a Convolutional Neural Network which works with spectrograms of the audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d651bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS \n",
    "\n",
    "## Audio libraries (install if needed)\n",
    "\n",
    "import noisereduce as nr # for noise reduction\n",
    "import librosa # for feature extraction\n",
    "import pydub # for normalising audio\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from pydub import effects\n",
    "\n",
    "cwd = os.getcwd()\n",
    "database = cwd + '\\dataset\\MSP-IMPROV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac01e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 338368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "362fb3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 8.151 minutes\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "audios = []\n",
    "spectrograms = []\n",
    "emotions = {'S':'sad', 'A': 'angry', 'N':'neutral', 'H':'happy', 'X':'X', 'O': 'other'}\n",
    "max_len = 338368\n",
    "start = time.perf_counter()\n",
    "\n",
    "\n",
    "pat = cwd + '\\dataset\\Evalution.txt'\n",
    "with open(pat) as f:\n",
    "    contents = f.read()\n",
    "    lines = contents.split(';')\n",
    "\n",
    "for subdir, dirs, files in os.walk(database):\n",
    "    for file in files: \n",
    "        # Preprocessing\n",
    "        process = file.split('-')[-2]\n",
    "        if process in ['R', 'T']:\n",
    "            \n",
    "            y, sr = librosa.load(path = os.path.join(subdir,file), sr = None)\n",
    "            audio = AudioSegment.from_file(os.path.join(subdir,file)) \n",
    "\n",
    "            normalized = effects.normalize(audio)\n",
    "            full_normalized = (np.array(audio.get_array_of_samples(), dtype = 'float32')/32768*1000)\n",
    "            full_normalized = librosa.core.resample(full_normalized, orig_sr=22050, target_sr=22050, res_type='kaiser_best')\n",
    "            trim, ix = librosa.effects.trim(full_normalized, top_db=25,frame_length=256, hop_length=64)\n",
    "            full_normalized = np.pad(trim, (0, max_len - len(trim)),)\n",
    "            fin = nr.reduce_noise(full_normalized, sr=sr,)\n",
    "\n",
    "            # Create spectrogram:\n",
    "            stft_fin = librosa.stft(fin)\n",
    "            spectrogram = librosa.amplitude_to_db(abs(stft_fin)) \n",
    "            \n",
    "            file = '\\n\\nUTD'+file[3:-3]+'avi'\n",
    "            if file == '\\n\\nUTD-IMPROV-S01A-F02-R-FF01.avi':\n",
    "                file = '\\nUTD-IMPROV-S01A-F02-R-FF01.avi'\n",
    "            i = lines.index(file)+1\n",
    "            emotion = emotions[lines[i][1:]]\n",
    "            labels.append(emotion)\n",
    "            audios.append(fin)\n",
    "            spectrograms.append(spectrogram)\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f\"Total time taken: {(end - start)/60:0.3f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfe9cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('specs.npy', spectrograms)\n",
    "np.save('audios.npy', audios)\n",
    "np.save('labels.npy', labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1051cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save them so I can load instead of preprocessing every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee070f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = np.load('specs.npy')\n",
    "audios = np.load('audios.npy')\n",
    "labels = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to colab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
